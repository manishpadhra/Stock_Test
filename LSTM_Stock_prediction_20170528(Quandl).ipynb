{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1.  A guide for how to use the lstmstock.py\n",
    "\n",
    "This is a presentation of the simplest way to implement Long Short Term Memory for prediction of stock price. More codes are in the lstmstock.py file. It also fixed the problem of using pandas datareader to download stock data, which is currently unavailable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import all the module and function\n",
    "You can import all module one by one or import my lstmstock.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt2\n",
    "import pandas as pd\n",
    "from pandas import datetime\n",
    "import math, time\n",
    "import itertools\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import load_model\n",
    "import keras\n",
    "import h5py\n",
    "from keras import backend as K\n",
    "import quandl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2. Input of the model\n",
    "\n",
    "1. Quandl api key Obtained from https://www.quandl.com/product/WIKIP/WIKI/PRICES-Quandl-End-Of-Day-Stocks-Info Please login to use your key if you have one.\n",
    "\n",
    "2. Seq_len\n",
    "It is the window frame of the past data, how many days of past data would you like to be included in this model?\n",
    "\n",
    "3. Shape\n",
    "Please input the [seq_len, Amount of features, 1] to it to setup the model\n",
    "The amount of features will depend on how many moving average would you like to be included in this model.\n",
    "\n",
    "4. Dropout\n",
    "Fraction of the input units to drop. It helps to avoid overfitting.\n",
    "\n",
    "5. Decay\n",
    "Weight regularization. Another parameter to avoid overfitting.\n",
    "\n",
    "6. Epochs\n",
    "How many Epochs would you want to fit the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quandl.ApiConfig.api_key = '8CDL22eUyzxYBQEwLNzF'\n",
    "seq_len = 22\n",
    "shape = [seq_len, 7,1]#[seq_len, 9, 1]\n",
    "neurons = [256, 256, 32, 1]\n",
    "dropout = 0.3\n",
    "decay = 0.5\n",
    "epochs = 90\n",
    "stock_name = 'AAPL'\n",
    "# quandl.ApiConfig.api_key = '8CDL22eUyzxYBQEwLNzF'\n",
    "# quandl.get('NSE/ASTRON', start_date='2017-12-29', end_date='2017-12-29')\n",
    "# quandl.get('NSE/ASTRON', column_index='1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Pull the data from Quandl first\n",
    "\n",
    "If you would like to include moving average, simply put the number of days into a list. \n",
    "They will be included into the neural network model.\n",
    "\n",
    "ie. putting 50days, 100days, 200days into [50, 100, 200]\n",
    "\n",
    "In the Quandl database, Open, High, Low, Close, Volume are all adjusted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stock_data(stock_name, normalize=True, ma=[]):\n",
    "    \"\"\"\n",
    "    Return a dataframe of that stock and normalize all the values. \n",
    "    (Optional: create moving average)\n",
    "    \"\"\"\n",
    "    df = quandl.get_table('WIKI/PRICES', ticker = stock_name)\n",
    "    df.drop(['ticker', 'open', 'high', 'low', 'close', 'ex-dividend', 'volume', 'split_ratio','adj_volume'], 1, inplace=True)\n",
    "\n",
    "    #df.drop(['ticker', 'open', 'high', 'low', 'close', 'ex-dividend', 'volume', 'split_ratio'], 1, inplace=True)\n",
    "    df.set_index('date', inplace=True)\n",
    "    \n",
    "    # Renaming all the columns so that we can use the old version code\n",
    "    df.rename(columns={'adj_open': 'Open', 'adj_high': 'High', 'adj_low': 'Low', 'adj_close': 'Adj Close'}, inplace=True)\n",
    "    #df.rename(columns={'adj_open': 'Open', 'adj_high': 'High', 'adj_low': 'Low', 'adj_volume': 'Volume', 'adj_close': 'Adj Close'}, inplace=True)\n",
    "    \n",
    "    # Percentage change\n",
    "    #df['Pct'] = df['Adj Close'].pct_change()\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    # Moving Average    \n",
    "    if ma != []:\n",
    "        for moving in ma:\n",
    "            df['{}ma'.format(moving)] = df['Adj Close'].rolling(window=moving).mean()\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    if normalize:\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        df['Open'] = min_max_scaler.fit_transform(df.Open.values.reshape(-1,1))\n",
    "        df['High'] = min_max_scaler.fit_transform(df.High.values.reshape(-1,1))\n",
    "        df['Low'] = min_max_scaler.fit_transform(df.Low.values.reshape(-1,1))\n",
    "        #df['Volume'] = min_max_scaler.fit_transform(df.Volume.values.reshape(-1,1))\n",
    "        df['Adj Close'] = min_max_scaler.fit_transform(df['Adj Close'].values.reshape(-1,1))\n",
    "        #df['Pct'] = min_max_scaler.fit_transform(df['Pct'].values.reshape(-1,1))\n",
    "        if ma != []:\n",
    "            for moving in ma:\n",
    "                df['{}ma'.format(moving)] = min_max_scaler.fit_transform(df['{}ma'.format(moving)].values.reshape(-1,1))  \n",
    "                \n",
    "    # Move Adj Close to the rightmost for the ease of training\n",
    "    adj_close = df['Adj Close']\n",
    "    df.drop(labels=['Adj Close'], axis=1, inplace=True)\n",
    "    df = pd.concat([df, adj_close], axis=1)\n",
    "      \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = get_stock_data(stock_name, ma=[50, 100, 200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Visualize the data\n",
    "Print out the first 5 rows of the dataframe and plot out the Adjusted Close price and percentage change of that particular stock "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_stock(df):\n",
    "    print(df.head())\n",
    "    plt.subplot(211)\n",
    "    plt.plot(df['Adj Close'], color='red', label='Adj Close')\n",
    "    plt.legend(loc='best')\n",
    "    #plt.subplot(212)\n",
    "    #plt.plot(df['Pct'], color='blue', label='Percentage change')\n",
    "    #plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Open      High       Low      50ma     100ma     200ma  \\\n",
      "date                                                                     \n",
      "1981-09-29  0.000337  0.000343  0.000348  0.000691  0.000964  0.000952   \n",
      "1981-09-30  0.000347  0.000353  0.000358  0.000676  0.000953  0.000945   \n",
      "1981-10-01  0.000347  0.000353  0.000358  0.000661  0.000941  0.000940   \n",
      "1981-10-02  0.000452  0.000458  0.000463  0.000650  0.000931  0.000935   \n",
      "1981-10-05  0.000494  0.000509  0.000505  0.000640  0.000922  0.000931   \n",
      "\n",
      "            Adj Close  \n",
      "date                   \n",
      "1981-09-29   0.000345  \n",
      "1981-09-30   0.000355  \n",
      "1981-10-01   0.000355  \n",
      "1981-10-02   0.000459  \n",
      "1981-10-05   0.000500  \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1902581f358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_stock(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. To see the correlation for each variables\n",
    "Not so ideal but more fundamental data will be included in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEhCAYAAABoTkdHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xu8XGV97/HPdwdEIMhNyeEeFGiJCAghXrEqokCpoFWE\nKqACqRYsak8Fra21gsbL6SleaRQk2iKigFBLuYhyUYFwC4RwkZwAQoygoiJECEm+54/1bBg2e+/M\nIjN7zUy+b17rNWuetdbMbzYwv3ku63lkm4iIiHYNNR1ARET0lySOiIioJYkjIiJqSeKIiIhakjgi\nIqKWJI6IiKgliSMiok9IOk3SA5JuGeO4JH1e0kJJN0vaveXYvpLuKMdOaCnfRNIlku4sjxuvKo4k\njoiI/nE6sO84x/cDdijbTOArAJImAV8qx6cBh0qaVq45AbjU9g7ApeX5uJI4IiL6hO0rgAfHOeVA\n4BuuXA1sJGlzYAaw0PYi28uAM8u5w9fMKftzgINWFUcSR0TE4NgSuLfl+X2lbKxygCm2l5T9XwJT\nVvUma61+nP1n3W0O7bl5VqTk8Lq22GO8Gntz1j1oatMhjOqmwzZpOoQxbTB1VtMhjOqRe76p1X2N\nOt83j9575l9TNTENm2179urG0C7blrTKeNfIxBERMVHq/CgsSWJ1EsViYOuW51uVsrXHKAe4X9Lm\ntpeUZq0HVvUm+ZkbEdFFYqjtrQPOBw4vo6teCvy+NENdC+wgaTtJzwIOKecOX3NE2T8COG9Vb5Ia\nR0REF3WyGVrSt4BXA8+VdB/wMaraBLZPAS4A9gcWAkuBd5VjyyUdC1wETAJOs72gvOws4CxJRwL3\nAAevKo4kjoiILupk4rB96CqOGzhmjGMXUCWWkeW/AfauE0cSR0REF0mr3b/ec5I4IiK6SBq8r9nB\n+0QRET1kEIfaJ3FERHRRh0ZL9ZQkjoiILkqNIyIiakniiIiIWgYxcTTyiSRtJem8Mv/7/5N0crmb\nMSJioAxpUttbv5jwxKFqUPM5wPfK/O87ApOBkyY6loiIbpOG2t76RRNNVa8FHrX9dQDbKyR9ALhL\n0l3AG4ANqab8/Q/bHweQ9A7gb4FnAdcAf1OufRg4GTgA+CNwoO37J/pDRUSMpp8SQrua+EQvBK5v\nLbD9EPBzqkQ2A/hLYBfgrZKmS9oJeBvwCtu7ASuAt5fL1weutr0rcAVw9IR8ioiItgzV2PpDL3aO\nX1LmTkHSOcArgeXAHsC15fb9dXly6t9lwPfL/vXAPqO9qKSZlHnu19p4OmtN3r5b8UdEPGEQaxxN\nJI5bgbe0Fkh6DrANVYIYuYiIAQFzbH94lNd7vEzsBVVNZNTP1DrPfS8u5BQRg2loAKccaSIVXgqs\nJ+lweGIR9f9DtQj7UmAfSZtIWpdq7duflGveImmzcs0mkrZtIPaIiFoGsXN8wiMttYM3UfVf3An8\nDHgU+Eg5ZS5wNnAzcLbt62zfCnwUuFjSzcAlwOYTHXtERF2S2t76RSN1KNv3An8xsrz84e6zfdAo\n13wb+PYo5ZNb9r8LfLejwUZErIZ+qkm0a/Aa3yIiekgmOewy26dT9XVERAyE1DgiIqKWQRxVNXif\nKCKil6TGERERdaSpKiIiaumnYbbtSuKIiOiijKqKiIha0lQVERH1TEpTVURE1JE+jsHQi1VHe2XT\nIYypF/9eAKzszUmOlz/em3Gt8LKmQxiT6d3//ldbEkdERNTSo7+7VkcSR0REFzk1joiIqCWd4xER\nUUtqHBERUcvg5Y0kjoiIrhoavMwxgP39ERE9RGp/a+vltK+kOyQtlHTCKMc3lnSupJslzZW0c8ux\n4yTdImmBpPe3lO8m6WpJ8yRdJ2nGeDEkcUREdJNqbKt6KWkS8CVgP2AacKikaSNO+wgwz/YuwOHA\nyeXanYGjgRnArsABkrYv13wG+Ljt3YB/Ks/HlMQREdFNk9T+tmozgIW2F9leBpwJHDjinGnADwFs\n3w5MlTQF2Am4xvZS28uBy4E3l2sMPKfsbwj8YrwgkjgiIrrIUttbG7YE7m15fl8pa3UTJSGUJqdt\nga2AW4C9JG0qaT1gf2Drcs37gc9Kuhf4HPDh8YJI4oiI6KYhtb1Jmln6GIa3mc/gHWcBG0maB7wP\nuBFYYfs24NPAxcCFwDxgRbnmvcAHbG8NfAA4dbw3aHRUlaSHbU9uef5OYLrtYyW9B1hq+xvjXP/E\n+V0PNiLimagxqMr2bGD2OKcs5slaAlQ1icUjXuMh4F0AqlaRugtYVI6dSkkKkj5JVWMBOAI4rux/\nB/jaeHH27HBc26c0HUNExGrr7A2A1wI7SNqOKmEcAvzVU99OG1H96F4GHAVcUZIJkjaz/YCkbaia\ns15aLvsF8GfAZcBrgTvHC6JnE4ekfwYetv05SXtSZcmVwCXAfraHh5htIelC4AXAubY/1EjAERGj\n6eCUI7aXSzoWuAiYBJxme0FpoRn+wb0TMEeSgQXAkS0vcbakTYHHgWNs/66UHw2cLGkt4FFg3Cay\nphPHuqUdbtgmwPmjnPd14GjbV0maNeLYbsCLgceAOyR9wfa9T3uFiIgmdHjKEdsXABeMKDulZf8q\nYMcxrt1rjPIfA3u0G0PTneN/tL3b8EY1fvgpSrVrg/LHADhjxCmX2v697UeBW6lGEDxNa6fT8ocX\ndvIzRESMrcM3APaCphNHJzzWsr+CMWpRtmfbnm57+lqTtx/tlIiIzhuqsfWJng+1tMH9QdJLStEh\nTcYTEVHLANY4mu7jaNeRwFclraS62/H3DccTEdGe/skHbWs0cbTew1Genw6cXvb/ueXQgjLvCmVS\nr+tGnl+eH9DFcCMiavOknm/Yqa1fahx/LunDVPHeA7yz2XAiItqUGkczbH8b+HbTcURE1DaA63H0\nReKIiOhbfdTp3a4kjoiIbhq8vJHEERHRVWmqioiIOtzBuap6RRJHREQ3pcYRERG1pHM8IiJqSY0j\nIiJqGbwbx5M4eoXUu/912SubDmF060xqOoJRrbtub/7CXHto/aZDWDNlypGIiKjD6eOIiIhaBq/C\nkcQREdFV6RyPiIha0lQVERG1pMYRERF1ZMqRiIioJzWOiIioJX0cERFRS4bjRkRELalxRERELenj\n6C5JD9ue3HQcERGd4sxVFRERtQxe3uj9jyRpqqQfSrpZ0qWStpE0SdJdqmwkaYWkV5Xzr5C0Q9Nx\nR0QAVR9Hu1uf6PnEAXwBmGN7F+A/gc/bXgHcAUwDXgncAOwlaR1ga9t3NhZtRESrIbW/9Yl+SBwv\nA84o+9+kShQAVwKvKtunSvmewLWjvYikmZKuk3Td8ocXdjfiiIhhSRw95QpgL2AGcAGwEfBqqoTy\nNLZn255ue/pak7efsCAjYs3mSWp76xf9kDh+ChxS9t/Ok4lhLvByYKXtR4F5wF9TJZSIiN7Q4T4O\nSftKukPSQkknjHJ8Y0nnln7huZJ2bjl2nKRbJC2Q9P4R171P0u3l2GfGi6HXRlWtJ+m+luf/CrwP\n+Lqkvwd+BbwLwPZjku4Fri7nXgkcCsyfwHgjIsbXwSYoSZOALwH7APcB10o63/atLad9BJhn+02S\n/rScv3dJIEdTtdIsAy6U9H3bCyW9BjgQ2LV8t242Xhw9lThsj1UDeu0Y5+/Vsn8GT/aFRET0hs62\nQM0AFtpeBCDpTKov/NbEMQ2YBWD79jIydQqwE3CN7aXl2suBNwOfAd4LzLL9WLnugfGC6IemqoiI\nvjU01P7WOoinbDNHvNyWwL0tz+8rZa1uokoISJoBbAtsBdxCNfp0U0nrAfsDW5drdizHrpF0uaQ9\nx/tMPVXjiIgYNHVuz7A9G5i9mm85CzhZ0jyqpvsbgRW2b5P0aeBi4BGqfuEV5Zq1gE2Al1KNTj1L\n0vNte7Q3SOKIiOiioc4Os13Mk7UEqGoSi1tPsP0QpS9YkoC7gEXl2KnAqeXYJ6lqLJTHc0qimCtp\nJfBcqn7lp0lTVUREF3V4UNW1wA6StpP0LKoRp+c/9f20UTkGcBRwRUkmDHd6S9qGqjlruF/4e8Br\nyrEdgWcBvx4riNQ4IiK6qJMzidheLulY4CJgEnCa7QWS3lOOn0LVCT5HkoEFwJEtL3G2pE2Bx4Fj\nbP+ulJ8GnCbpFqoRV0eM1UwFSRwREV2lDrfr2L6A6qbn1rJTWvavoursHu3avcYoXwa8o90Ykjgi\nIrqoj+YubFsSR0REF/XRFFRtS+KIiOiioQEcgpTEERHRRRrAtqo1MnFssce+TYfwdCvHHMDQvHUm\nNR3BqBZf9f2mQxjVyjvHvem2MYdvuUfTIYxpixn7NR1C13S6c7wXrJGJIyJiogxghSOJIyKim5I4\nIiKilklpqoqIiDpS44iIiFqSOCIiohYN4B2ASRwREV2UGkdERNSSxBEREbVkVFVERNSSGkdERNSS\nKUdWk6S7gT9QLZC+3PZ0SZsA3wamAncDB9v+7UTGFRHRLYNY42giF77G9m62p5fnJwCX2t4BuLQ8\nj4gYCJLa3vpFLzRVHQi8uuzPAS4Djpf0TuAgYH1gB+BzVAuoHwY8Buxv+0FJRwMzy7GFwGG2l05g\n/BERY+qjfNC2ia5xGPiBpOslzSxlU2wvKfu/BKa0nL8z8GZgT+AkYKntFwNXAYeXc86xvaftXYHb\neOrC7BERjRoaan/rFxNd43il7cWSNgMukXR760HbltS6MMWPbP8B+IOk3wP/VcrnA7uU/Z0lnQhs\nBEwGLhrtjUuimgnwvN3exXO2e03HPlRExFgG8Mbxia1x2F5cHh8AzgVmAPdL2hygPD7QcsljLfsr\nW56v5MmkdzpwrO0XAR8Hnj3Ge8+2Pd329CSNiJgoQ2p/6xcTljgkrS9pg+F94PXALcD5wBHltCOA\n82q+9AbAEklrA2/vULgRER0xJLe99YuJbKqaApxbRg6sBZxh+0JJ1wJnSToSuAc4uObr/iNwDfCr\n8rhB50KOiFg9/VSTaNeEJQ7bi4BdRyn/DbD3KOWnUzVDDT+fOtox218BvtLZaCMiOmOtPqpJtKsX\nhuNGRAys1DgiIqKWPhpl27YkjoiILkqNIyIialH6OCIioo7UOCIiopaMqoqIiFoGscYxiB3+ERE9\nY6jG1g5J+0q6Q9JCSU9bhkLSxpLOlXSzpLmSdm45dpykWyQtkPT+Ua79O0mW9NxVfaaIiOiSTs5V\nJWkS8CVgP2AacKikaSNO+wgwz/YuVLOIn1yu3Rk4mmqOwF2BAyRt3/LaW1NNBfXzVX6mVYcaERHP\nVIfnqpoBLLS9yPYy4EyqNY1aTQN+CGD7dmCqpCnATsA1tpfaXg5cTrVsxbD/C3yIavmLca2RfRzr\nHjS16RCeZvnjvduBtu66vdlIu/LOPZsOYVRLfn1t0yGM6ienbtl0CGNa/43bNh1C16zV2f99tgTu\nbXl+H/CSEefcRJUQrpQ0A9gW2IpqUtmTJG0K/BHYH7gOQNKBwGLbN7WzEuEamTgiIiZKnVlvW9cN\nKmbbnl3zLWcBJ0uaR7V20Y3ACtu3Sfo0cDHwCDAPWCFpParmrde3+wZJHBERXVRnVFVJEuMlisXA\n1i3Ptyplra/xEPAuAFXVh7uAReXYqcCp5dgnqWosLwC2A4ZrG1sBN0iaYfuXowWRxBER0UUdHo57\nLbCDpO2oEsYhwF+1niBpI6pltpcBRwFXlGSCpM1sPyBpG6rmrJfa/h2wWcv1dwPTbf96rCCSOCIi\nuqiTI5BsL5d0LNUS2ZOA02wvkPSecvwUqk7wOWUZ7gXAkS0vcXbp43gcOKYkjdqSOCIiuqjTK/vZ\nvgC4YETZKS37VwE7jnHtXm28/tRVnZPEERHRRR0eVdUTkjgiIrpoEKccSeKIiOiiTKseERG1pMYR\nERG1DOK8TkkcERFd1OlRVb2g48lQ0mmSHpB0S0vZJpIukXRnedy45diHy/TAd0h6Q6fjiYho0lpD\n7W/9ohuhng7sO6LsBOBS2zsAl5bnlOmADwFeWK75cpk2OCJiIEyqsfWLjicO21cAD44oPhCYU/bn\nAAe1lJ9p+zHbdwELqaYNRtLDkj5bFhz5gaQZki6TtEjSG8s5UyVdKemGsr28058nImJ1dHha9Z4w\nUZWjKbaXlP1fAlPK/mhTBA/P/bw+8EPbLwT+AJwI7AO8CfiXcs4DwD62dwfeBny+a58gIuIZ6ORC\nTr1iwlvVbJs2FgoBlgEXlv35wOW2Hy/7U0v52sBXJc0HvkO1gMmoJM2UdJ2k6x780fnPNPyIiFoG\nMXFM1Kiq+yVtbnuJpM2pagow/hTBj5ckA7ASeAzA9kpJw3F/ALifahnEIeDRsQJona74Rd+4sn/q\nhBHR19buo07vdk3URzofOKLsHwGc11J+iKR1yjTBOwBza7zuhsAS2yuBw+iv/qWIWAMMYh9Hx2sc\nkr4FvBp4rqT7gI9RrUh1lqQjgXuAgwHKdMBnAbcCy6mm+V1R4+2+TDVN8OFUzVqPdOyDRER0QD81\nQbWr44nD9qFjHNp7jPNPAk4apXxyy/4/j3bM9p3ALi2Hjq8ZbkREVw1iM0juHI+I6KLUOCIiopZ+\n6rtoVxJHREQXDeKoqiSOiIguSlNVRETUksQRERG1TEofR0RE1DGAXRxJHBER3ZSmqoiIqGXtoTRV\nRUREDalxDIibDtuk6RCeZoWXNR3CmNYeWr/pEEZ1+JZ7NB3CqH5y6parPqkBv7jse02HMKZH5vxj\n0yF0TRJHRETUksQRERG1TEriiIiIOtbKfRwREVFHmqoiIqKWNFVFREQtmVY9IiJqGcSmqkGcRiUi\nomcMqf2tHZL2lXSHpIWSThjl+MaSzpV0s6S5knZuOXacpFskLZD0/pbyz0q6vVxzrqSNxv1M7X/8\niIioa5La31ZF0iTgS8B+wDTgUEnTRpz2EWCe7V2Aw4GTy7U7A0cDM4BdgQMkbV+uuQTYuVzzM+DD\n48WRxBER0UWqsbVhBrDQ9iLby4AzgQNHnDMN+CGA7duBqZKmADsB19heans5cDnw5nLexaUM4Gpg\nq/GCSOKIiOgiqf2tDVsC97Y8v6+UtbqJkhAkzQC2pUoEtwB7SdpU0nrA/sDWo7zHu4H/GS+IjiYO\nSVtL+pGkW0sb2nGlfBNJl0i6szxu3HLNh0tb3R2S3tDJeCIimjZUY5M0U9J1LdvMZ/CWs4CNJM0D\n3gfcCKywfRvwaeBi4EJgHrCi9UJJ/wAsB/5zvDfo9Kiq5cDf2b5B0gbA9ZIuAd4JXGp7VunMOQE4\nvrTNHQK8ENgC+IGkHW2vGOP1IyL6imoMx7U9G5g9zimLeWotYatS1voaDwHvqt5bAu4CFpVjpwKn\nlmOfpKqxlDj1TuAAYG/b4wbd0RqH7SW2byj7fwBuo6pGHQjMKafNAQ4q+wcCZ9p+zPZdwEKqNjwk\nPVx6+hdI+oGkGZIuk7RI0hvLOVMlXSnphrK9vJOfJyJidXW4j+NaYAdJ20l6FtUP7/Of8n7SRuUY\nwFHAFSWZIGmz8rgNVXPWGeX5vsCHgDfaXrqqILp2H4ekqcCLgWuAKbaXlEO/BKaU/S2pOmKGtbbX\nrQ/80PbfSzoXOBHYh6rjZw7VH+sBYB/bj0raAfgWML1bnykioq5O3sdhe7mkY4GLgEnAabYXSHpP\nOX4KVSf4HFVVnQXAkS0vcbakTYHHgWNs/66UfxFYB7ikqqRwte33jBVHVxKHpMnA2cD7bT+kll4f\n21Z7dbdlVO1wAPOBx2w/Lmk+MLWUrw18UdJuVG11O44T00xgJsBXTvkYM2e+td6Hioh4Bjp9A6Dt\nC4ALRpSd0rJ/FWN8F9rea4zy7UcrH0vHE4ektamSxn/aPqcU3y9pc9tLJG1OVVOA8dvrHm9pZ1sJ\nPAZge6Wk4bg/ANxPNSZ5CHh0rLha2w5XesHgzQEQET1pAG8c7/ioKlF1vNxm+19bDp0PHFH2jwDO\nayk/RNI6krYDdgDm1njLDYEltlcCh1FV3SIiekaHh+P2hE7XOF5B9QU+vwwFg+ouxlnAWZKOBO4B\nDgYobXNnAbdSjcg6puaIqi9TtdkdTtWs9UhnPkZERGf0UT5oW0cTh+0fM/bfae8xrjkJOGmU8skt\n+/882jHbdwK7tBw6vl7EERHdlWnVIyKilgHMG0kcERHdVOcGwH6RxBER0UWpcURERC39NFqqXUkc\nERFdNIhTkCdxRER00SAuHZvEERHRRWmqioiIWgYwbyRxRER0U5qqIiKilgHMG2tm4thg6qymQ3ga\ns7LpEPrOFjP2azqEUa3/xm2bDmFUj8z5x6ZDGNP6236i6RBG9ceff2u1X2MoNwBGREQd6RyPiIha\nBjBvJHFERHRTbgCMiIha0lQVERE1DV7mSOKIiOiiIQ3eitZJHBERXZUaR0RE1KAkjoiIqCeJIyIi\napAGb0BuEkdERFcNXo2jrVQo6SBJlvSn45xzuqS3lP2vSZo2yjlrS5ol6U5JN0i6StJ+5djdkp77\nTD9IREQvGqrxT79oN9JDgR+Xx1WyfZTtW0c59Algc2Bn27sDBwEbtBlDREQfGqqx9YdVRippMvBK\n4EjgkJZySfqipDsk/QDYrOXYZZKmj3id9YCjgffZfgzA9v22zxrlPT8o6Zayvb+UrS/pvyXdVMrf\nVsr3kHS5pOslXSRp82fyh4iI6AZJbW/9op0+jgOBC23/TNJvJO1h+3rgTcCfANOAKcCtwGnjvM72\nwM9tPzTem0naA3gX8BKqxsFrJF0OPB/4he0/L+dtKGlt4AvAgbZ/VZLJScC72/hcEREToH8SQrva\nqRsdCpxZ9s/kyeaqVwHfsr3C9i+AH3YoplcC59p+xPbDwDnAXsB8YB9Jn5a0l+3fUyWunYFLJM0D\nPgpsNdqLSpop6TpJ1y1/+M4OhRoRMT7V+KdfjFvjkLQJ8FrgRZIMTAIs6e+fwXstBLaR9JxV1TpG\nU2o8uwP7AydKuhQ4F1hg+2VtXD8bmA2w/raHDd7KKhHRk8TgTTmyqhrHW4Bv2t7W9lTbWwN3UdUA\nrgDeJmlS6Vd4zXgvZHspcCpwsqRnAUh6nqS3jjj1SuAgSetJWp+qSexKSVsAS23/B/BZYHfgDuB5\nkl5WXm9tSS9s/+NHRHTXIPZxrCpxHEr1q77V2S3ld1L1bXwDuGrEeaP9qv8o8CvgVkm3AN8HnlL7\nsH0DcDowF7gG+JrtG4EXAXNLk9THgBNtL6NKbp+WdBMwD3j5Kj5TRMQEUo2tjVeT9i2DkhZKOmGU\n4xtLOlfSzZLmStq55dhxZXDRguGBR6V8E0mXlFslLpG08bgx2J1vtZE0H3ij7bs6/uId0ItNVVlz\nvL5eXXN8vR5dc3zeOzZtOoQx9fCa46tdDXhsxdy2v2/WmTRj3PeTNAn4GbAPcB9wLXBo6+0Pkj4L\nPGz74+Xeuy/Z3rskkDOBGcAy4ELgPbYXSvoM8KDtWSUZbWz7+LHi6PjAYUmXAPN7NWlEREysjtY4\nZgALbS8qLS5nUo18bTWNMljJ9u3AVElTgJ2Aa2wvtb0cuBx4c7nmQGBO2Z9DdY/dmDqeOGzvY/uv\nOv26ERH9qMN9HFsC97Y8v6+UtbqJkhAkzQC2pRpteguwl6RNy311+wNbl2um2F5S9n9JdYvFmDJX\nVUREF9UZVSVpJjCzpWh2GRFaxyyqQUjzqG5juBFYYfs2SZ8GLgYeoeoTXjHyYtsuo2jHlMQREdFV\n7XeTtN42MIbFPFlLgKomsXjEazxEdRM1qqoxdwGLyrFTqUa3IumTVDUWgPslbW57SRkl+8B4cfbP\n5CgREX2owzcAXgvsIGm7clvDIcD5T3k/aaPhWx6Ao4Arhu+dk7RZedyGqjnrjHLe+cARZf8I4Lzx\ngkiNIyKiizp5f4bt5ZKOBS6iuiH7NNsLJL2nHD+FqhN8TmluWkA1z+CwsyVtCjwOHGP7d6V8FnCW\npCOBe4CDx4sjiSMioqs627Bj+wLgghFlp7TsXwXsOMa1e41R/htg73ZjSOKIiOiifpqDql1JHBER\nXZSlYyMioqbBSxxdmXJkTSJp5jMYZ911iaueXo0Leje2xLXmGrxUOPFmrvqURiSueno1Lujd2BLX\nGiqJIyIiakniiIiIWpI4Vl+vtqUmrnp6NS7o3dgS1xoqneMREVFLahwREVFLEkdERNSSxBEREbUk\ncUTXSXpB0zHE4JI0RdKpkv6nPJ9WZnmNLknneE2SngccDUylZcoW2+9uKqZWkrakWiqyNbYrmosI\nJF1OteDMtcCVVOsDzG8yJgBJz6aacvqFwLOHy3vl32W0pySMrwP/YHtXSWsBN9p+UcOhDazMVVXf\neVRffj9glGUXm1SWhXwbcCtPxmag0cRh+8/KwjJ7Aq8G/lvSZNubNBkX8E3gduANwL8AbwduazSi\nHifppcAXqNZ8eBbVmhCP2H5Og2E91/ZZkj4MT6xZ0VP/bw6aJI761rN9fNNBjOEg4E9sP9Z0IK0k\nvRLYq2wbAd+nSr5N2972WyUdaHuOpDPojbh69Qsa4ItUq859B5gOHM4Yaz9MoEfK4kSGJ/52v282\npMGWxFHf9yXtXxZT6TWLgLWBnkocwGXA9cCngAtsL2s2nCc8Xh5/J2ln4JfAZg3G06oXv6ABsL1Q\n0iTbK4CvS7oR+HCDIX2QaunTF0j6CfA84C0NxjPw0sdRk6Q/AOsDy8omwE3+EpT0BapfW1sCuwKX\n0pI8bP9tQ6EB1RrIwCuAV1E1V60ErrL9jw3HdRRwNrALVRv5ZOCfWldTa4qk62xPl3Sz7V1K2Y22\nX9xwXFcArwO+RpVolwDvtL1rw3GtBfwJ1f+Pd9h+fBWXxGpIjaMm2xs0HcMoriuP1zNi4fpeYPt3\nkhYBW1N1kr+cqmbUKNtfK7uXA89vMpZRLC39QvMkfYbqC7oXRkEeRtVsdizwAap/p3/ZZECS3gpc\nWNbe/iiwu6QTbd/QZFyDLDWOmlStPP92YDvbn5C0NbC57bkNh9azStK4HfgxVUf93F5orio1ocN5\n+gi5RmtoAJK2BR6gSrAfADYEvmx7YaOB9aDhWlnpS/sE8DmqmuNLGg5tYCVx1CTpK1RNLa+1vZOk\njYGLbe8OrNpbAAAIc0lEQVTZcGhImk/pIGzxe6oayYllQfoJJ2nI9som3ns8kn4KXA3Mp/p3CoDt\nOY0F1eMkHUD15Tw85LsXmmpvtP1iSZ8C5ts+oxea9QZZmqrqe4nt3UuHILZ/W5oUesH/UA3DPaM8\nPwRYj6ot+nTgL5oJiy1KP8wryvMrgeNs39dQPMOebfuDDccwql78gi7+DXgz1Rd0r/zqXCzp34F9\ngE9LWofeaNYbWEkc9T0uaRJPDv17Hi2/Vhv2Otu7tzyfL+mGkuje0VhUVcfzGcBby/N3lLJ9Gouo\n8k1JR1MND24dTPBgcyE9oRe/oAHuBW7psZgOBvYFPlf60zYH/r7hmAZaEkd9nwfOBaZIOolq2N9H\nmw3pCZMkzRjub5G0J1VHJsDy5sLieba/3vL8dEnvbyyaJy0DPgv8A0828Zne6CjvxS9ogA8BF5TZ\nAFqT7b82FZDtpZL+H/AGSW8ArrR9cVPxrAmSOGqy/Z+Srgf2LkUH2e6Vu42PAk6TNJmqaeMh4ChJ\n61PdQ9GU35Qaz7fK80OBRvpbRvg7qpsAf910IKPouS/o4iTgYaopWnqiiVbScVTTAJ1Tiv5D0mzb\nX2gwrIGWzvFnQNLuwCupfp3+pNeG/UnaEMB2T9w9W0YIfQF4GdXf7KfA+2zf23BcF1Ml/qVNxjGa\nEtvDPL3j/uONBQVIusX2zk3GMJKkm4GX2X6kPF+f6j6hXZqNbHClxlGTpH+iaqs/m+pX/dclfcf2\niQ3G9A7b/yHpgyPKgeZ/pdq+B3hja1lpqvq3ZiJ6wiNU90n8iB66YbLYote+oIsLJL2+x5qCxFPn\njVtRyqJLkjjqezuwq+1HASTNAuYBjSUOqjvZAXrx5sSxfJDmE8f3ytaLevELGuC9wP+W9BjVlC29\nMNrr68A1ks4tzw8CTm0wnoGXpqqayq/TN9n+XXm+EXCO7dc2G1l/kXSv7a2bjqNXtUxt00tf0D2r\npfkYqs7xG5uMZ9AlcdQk6XtU8y1dUopeB8wF7oNmmjkkfX684z3S9PIUkn5ue5uG3ntDqkn5DqKa\n1NBUd2mfB8wa/lEQT1VmTZhBNScawGKqWQAa+RKRNO60/D0yrHogpamqvouoJhE01RDXHzUbDlDN\nUTXs48DHmgqkVfnVPNqXioB1JzicVmcBPwRebfuXAJL+F/DOcuz1zYXWe1/QJabXA18G7izxQDXv\n2PaS/qahJrXrqf77Gu7PGP77iN4ZVj2QUuNoU5l985PAu4F7qP7j3IaqffUjvTIbZ6ZaWDVJd9j+\nk7rHJsJ4X9BAU1/QSLoN2M/23SPKt6OaKn+nJuKKZqTG0b7PUnU+b2f7DwCSnkM1odpngV64oQ1G\n/4UfT3WPpA8Bc2zfD9W61VQ1jkaHCAMnU80AcHdr4fAXNNXCTk1Yi9IcO8JiGprpuNzst4Ht744o\n/0vgIduXjH5lrK4kjvYdAOzY2lxg+yFJ76Wa+bVXEkes2tuAE4DLS8IwcD/VlPQHNxkYPfgFXZwG\nXCvpTJ5MrltTzYfW1Aimf6LqpxrpcuC/eLIfMjosiaN9Hq2N2fYKSY3+yh/Rl7CepIeGD5GROE9j\n+7fA8WVD0l5UfQrze6BDtRe/oLH9KUnnUd2P87JSvBh4u+1bGwprHdu/Gllo+9flJsDokvRxtKmM\npjrH9jdGlL8DONj2G0e/MnqNpLm2Z5T9o4BjqO7neD3wX7ZnNRzfNKov6NbO8fMb/ILuSZJ+Bkyz\nvXxE+drArbZ3aCaywZfE0SZJW1LNhfNHnhzFNJ1qdNCbbC8e69roLa0DCCRdC+xv+1flV+rVtl/U\nbIS9pxeHMJebb6cAx7ZMNzKZqp/o17aPn+iY1hSZs75NtheXFcX+Bbi7bP9ie0aSRt8ZkrSxpE2B\nScPNHeXLp8lZhJG0oaRZkm6X9KCk30i6rZRt1GBoZwG/pRrCvIntTYHXlLKzGorpo1R9U/dIur5M\nPnoX8Ct6Z8bqgZQaR6xxJN1NNXHg8Hj/V9heUn6t/tj2bg3GdhHVPSZzRtxjcgSwt+1G7jHp8SHM\n61INVwZYaPuPTcWypkjiiCgkrQdMsX1XgzH05Bd0ma33B4w+hHkf269rIq5oRpqqIgrbS5tMGsU9\nkj5UvpSB6gta0vE0e4/J24BNqYYw/1bSg8BlwCY0P4Q5JlhqHBE9RNLGVPeYHEjVCQ1P3mMyqwwl\nbiq2P6W6i/1q2w+3lO9r+8Km4oqJl8QR0SckvWvEErwT+d5/SzVs+TZgN+A42+eVYzf4qWvdT1RM\nf2r79jIz7kgGHixrwUSHJXFE9ImGZxSeT7XK3sOSpgLfBb5p++Sm5keT9FXbR5elDkazKXCT7cMm\nMq41Qe4cj+ghZRnUUQ9R3bPQlKHh5inbd0t6NfDdsixwI6vt2T66PL5mrHNKp350WBJHRG+ZAryB\n6v6IVqJaq70p90vazfY8gFLzOIBqipRGbpiU9Obxjts+p6nhy4MuiSOit3wfmDz8Bd1K0mUTH84T\nDmfEzZFlqo/DJf17MyHxF+VxM+DlVPe/QHVj4k+pZnqILkgfR0T0tdIcdYTtJeX55sDptt/QbGSD\nK/dxRES/23o4aRT3Uy2yFl2SpqqI6HeXlqlavlWeH0J1l3t0SZqqIqLvSXoT8Kry9Arb5zYZz6BL\n4oiIgVIW5jrE9jFNxzKo0lQVEX1P0ouBQ6nmzbqLjKjqqiSOiOhLknakShaHAr8Gvk3VijLmDYHR\nGWmqioi+JGklcCVwpO2FpWyR7ec3G9ngy3DciOhXbwaWAD+S9FVJe9PQ9CdrmtQ4IqKvlbXiD6Rq\nsnot8A3gXNuZp6pLkjgiYmCU9UzeCrzN9t5NxzOokjgiIqKW9HFEREQtSRwREVFLEkdERNSSxBER\nEbUkcURERC3/H/vDhaTZLHckAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19025d70630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr = df.corr()\n",
    "ax = sns.heatmap(corr, cmap=\"YlGnBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Split out training set and testing set data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(stock, seq_len):\n",
    "    amount_of_features = len(stock.columns)\n",
    "    print (\"Amount of features = {}\".format(amount_of_features))\n",
    "    data = stock.as_matrix()\n",
    "    sequence_length = seq_len + 1 # index starting from 0\n",
    "    result = []\n",
    "\n",
    "    for index in range(len(data) - sequence_length): # maxmimum date = lastest date - sequence length\n",
    "        result.append(data[index: index + sequence_length]) # index : index + 22days\n",
    "\n",
    "    result = np.array(result)\n",
    "    row = round(0.8 * result.shape[0]) # 80% split\n",
    "    print (\"Amount of training data = {}\".format(0.9 * result.shape[0]))\n",
    "    print (\"Amount of testing data = {}\".format(0.1 * result.shape[0]))\n",
    "\n",
    "    train = result[:int(row), :] # 90% date\n",
    "    X_train = train[:, :-1] # all data until day m\n",
    "    y_train = train[:, -1][:,-1] # day m + 1 adjusted close price\n",
    "\n",
    "    X_test = result[int(row):, :-1]\n",
    "    y_test = result[int(row):, -1][:,-1]\n",
    "\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], amount_of_features))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], amount_of_features))\n",
    "\n",
    "    return [X_train, y_train, X_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train.shape)\n",
    "# print(y_train.shape)\n",
    "# print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of features = 7\n",
      "Amount of training data = 8210.7\n",
      "Amount of testing data = 912.3000000000001\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = load_data(df, seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Model Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(shape, neurons, dropout, decay):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(neurons[0], input_shape=(shape[0], shape[1]), return_sequences=True))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(LSTM(neurons[1], input_shape=(shape[0], shape[1]), return_sequences=False))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Dense(neurons[2],kernel_initializer=\"uniform\",activation='relu'))\n",
    "    model.add(Dense(neurons[3],kernel_initializer=\"uniform\",activation='linear'))\n",
    "    # model = load_model('my_LSTM_stock_model1000.h5')\n",
    "    adam = keras.optimizers.Adam(decay=decay)\n",
    "    model.compile(loss='mse',optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 22, 256)           270336    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 22, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 803,905\n",
      "Trainable params: 803,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(shape, neurons, dropout, decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5838 samples, validate on 1460 samples\n",
      "Epoch 1/90\n",
      "5838/5838 [==============================] - 32s 6ms/step - loss: 2.2235e-05 - acc: 1.7129e-04 - val_loss: 0.0092 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "5838/5838 [==============================] - 33s 6ms/step - loss: 1.6167e-05 - acc: 1.7129e-04 - val_loss: 0.0087 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "2048/5838 [=========>....................] - ETA: 21s - loss: 1.5222e-05 - acc: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-7feff10952d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     verbose=1)\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\manis\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 960\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32mC:\\Users\\manis\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1657\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Users\\manis\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\manis\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2357\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2358\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\manis\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\manis\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\manis\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\manis\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\manis\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=512,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Result on training set and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_score(model, X_train, y_train, X_test, y_test):\n",
    "    trainScore = model.evaluate(X_train, y_train, verbose=0)\n",
    "    print('Train Score: %.5f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n",
    "\n",
    "    testScore = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test Score: %.5f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))\n",
    "    return trainScore[0], testScore[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Prediction vs Real results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def percentage_difference(model, X_test, y_test):\n",
    "    percentage_diff=[]\n",
    "\n",
    "    p = model.predict(X_test)\n",
    "    for u in range(len(y_test)): # for each data index in test data\n",
    "        pr = p[u][0] # pr = prediction on day u\n",
    "\n",
    "        percentage_diff.append((pr-y_test[u]/pr)*100)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = percentage_difference(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def denormalize(stock_name, normalized_value):\n",
    "    \"\"\"\n",
    "    Return a dataframe of that stock and normalize all the values. \n",
    "    (Optional: create moving average)\n",
    "    \"\"\"\n",
    "    df = quandl.get_table('WIKI/PRICES', ticker = stock_name)\n",
    "    df.drop(['ticker', 'open', 'high', 'low', 'close', 'ex-dividend', 'volume', 'split_ratio'], 1, inplace=True)\n",
    "    df.set_index('date', inplace=True)\n",
    "    \n",
    "    # Renaming all the columns so that we can use the old version code\n",
    "    df.rename(columns={'adj_open': 'Open', 'adj_high': 'High', 'adj_low': 'Low', 'adj_volume': 'Volume', 'adj_close': 'Adj Close'}, inplace=True)\n",
    "    \n",
    "    df.dropna(inplace=True)\n",
    "    df = df['Adj Close'].values.reshape(-1,1)\n",
    "    normalized_value = normalized_value.reshape(-1,1)\n",
    "\n",
    "    #return df.shape, p.shape\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    a = min_max_scaler.fit_transform(df)\n",
    "    new = min_max_scaler.inverse_transform(normalized_value)\n",
    "      \n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def plot_result(stock_name, normalized_value_p, normalized_value_y_test):\n",
    "        newp = denormalize(stock_name, normalized_value_p)\n",
    "        newy_test = denormalize(stock_name, normalized_value_y_test)\n",
    "        plt2.plot(newp, color='red', label='Prediction')\n",
    "        plt2.plot(newy_test,color='blue', label='Actual')\n",
    "        plt2.legend(loc='best')\n",
    "        plt2.title('The test result for {}'.format(stock_name))\n",
    "        plt2.xlabel('Days')\n",
    "        plt2.ylabel('Adjusted Close')\n",
    "        plt2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(stock_name, p, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Finding the best hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quick_measure(stock_name, seq_len, dropout, shape, neurons, epochs, decay):\n",
    "    df = get_stock_data(stock_name)\n",
    "    X_train, y_train, X_test, y_test = load_data(df, seq_len)\n",
    "    model = build_model(shape, neurons, dropout, decay)\n",
    "    model.fit(X_train, y_train, batch_size=512, epochs=epochs, validation_split=0.2, verbose=0)\n",
    "    # model.save('LSTM_Stock_prediction-20170528.h5')\n",
    "    trainScore, testScore = model_score(model, X_train, y_train, X_test, y_test)\n",
    "    return trainScore, testScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quandl.ApiConfig.api_key = 'zpFWg7jpwtBPmzA8sT2Z'\n",
    "seq_len = 22\n",
    "shape = [seq_len, 6, 1] # Without moving average, 6 features will be used\n",
    "neurons = [256, 256, 32, 1]\n",
    "dropout = 0.3\n",
    "decay = 0.5\n",
    "epochs = 80\n",
    "stock_name = 'AAPL'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Testing for epochs\n",
    "Repeatedly test it and sum up the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-5585a7124caf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# while i < 5:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mepochslist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mtrainScore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestScore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquick_measure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstock_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneurons\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mepochs_train_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainScore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mepochs_test_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtestScore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "epochslist = [40,50,60,70,80,90,100,110,120,130,140,150]\n",
    "epochs_train_result = {}\n",
    "epochs_test_result = {}\n",
    "#i=0\n",
    "\n",
    "#for epochs in epochslist:   \n",
    "#    epochs_train_result[epochs] = 0\n",
    "#    epochs_test_result[epochs] = 0\n",
    "\n",
    "# while i < 5:\n",
    "for epochs in epochslist:    \n",
    "    trainScore, testScore = quick_measure(stock_name, seq_len, d, shape, neurons, epochs, decay)\n",
    "    epochs_train_result[epochs] = trainScore\n",
    "    epochs_test_result[epochs] = testScore\n",
    "#    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# epochs_train_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_train_val = min(epochs_train_result.values())\n",
    "min_train_val_key = [k for k, v in epochs_train_result.items() if v == min_train_val]\n",
    "print (epochs_train_result)\n",
    "print (min_train_val_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_test_val = min(epochs_test_result.values())\n",
    "min_test_val_key = [k for k, v in epochs_test_result.items() if v == min_test_val]\n",
    "print (epochs_test_result)\n",
    "print (min_test_val_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lists1 = sorted(epochs_test_result.items())\n",
    "x1,y1 = zip(*lists1)\n",
    "plt.plot(x1,y1)\n",
    "\n",
    "plt.title('Finding the best hyperparameter for testing')\n",
    "plt.xlabel('Dropout')\n",
    "plt.ylabel('Mean Square Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lists2 = sorted(epochs_train_result.items())\n",
    "x2,y2 = zip(*lists2)\n",
    "plt.plot(x2,y2)\n",
    "plt.title('Finding the best hyperparameter for training set')\n",
    "plt.xlabel('Dropout')\n",
    "plt.ylabel('Mean Square Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Testing for dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dlist = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "dropout_train_result = {}\n",
    "dropout_test_result = {}\n",
    "\n",
    "for d in dlist:    \n",
    "    trainScore, testScore = quick_measure(stock_name, seq_len, d, shape, neurons, epochs, decay)\n",
    "    dropout_train_result[d] = trainScore\n",
    "    dropout_test_result[d] = testScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_train_val = min(dropout_train_result.values())\n",
    "min_train_val_key = [k for k, v in dropout_train_result.items() if v == min_train_val]\n",
    "print (dropout_train_result)\n",
    "print (min_train_val_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_test_val = min(dropout_test_result.values())\n",
    "min_test_val_key = [k for k, v in dropout_test_result.items() if v == min_test_val]\n",
    "print (dropout_test_result)\n",
    "print (min_test_val_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lists1 = sorted(dropout_test_result.items())\n",
    "x1,y1 = zip(*lists1)\n",
    "plt.plot(x1,y1)\n",
    "plt.title('Finding the best hyperparameter for testing set')\n",
    "plt.xlabel('Dropout')\n",
    "plt.ylabel('Mean Square Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lists2 = sorted(dropout_train_result.items())\n",
    "x2,y2 = zip(*lists2)\n",
    "plt.plot(x2,y2)\n",
    "plt.title('Finding the best hyperparameter for training set')\n",
    "plt.xlabel('Dropout')\n",
    "plt.ylabel('Mean Square Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
